{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661ef964",
   "metadata": {},
   "source": [
    "CSV ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d54dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ì§ˆë¬¸</th>\n",
       "      <th>ë‹µë³€ë²ˆí˜¸</th>\n",
       "      <th>ë³„ì </th>\n",
       "      <th>í”¼ë“œë°±</th>\n",
       "      <th>ì¸ê³µì§€ëŠ¥ ë‹µë³€</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>í—¬ë¡œì›…</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ëª°ë¼.\\n</td>\n",
       "      <td>í—¬ë¡œ! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ë‚˜ í•„ìš”í•œ ì •ë³´ê°€ ìˆìœ¼ì‹œë‹¤ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì €ê¸°ìš”</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ëª°ë¼ã…ã…ã…ã…ã…</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”! LG AI Researchì˜ EXAONE ëª¨ë¸ì…ë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë‹¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì•ˆë…•</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ì˜ê°€</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š How can I assist you today? Feel free...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ì§ˆë¬¸  ë‹µë³€ë²ˆí˜¸  ë³„ì       í”¼ë“œë°±                                            ì¸ê³µì§€ëŠ¥ ë‹µë³€\n",
       "0  í—¬ë¡œì›…     1   3    ëª°ë¼.\\n  í—¬ë¡œ! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ë‚˜ í•„ìš”í•œ ì •ë³´ê°€ ìˆìœ¼ì‹œë‹¤ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´...\n",
       "1  ì €ê¸°ìš”     1   2  ëª°ë¼ã…ã…ã…ã…ã…  ì•ˆë…•í•˜ì„¸ìš”! LG AI Researchì˜ EXAONE ëª¨ë¸ì…ë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë‹¤...\n",
       "2   ì•ˆë…•     1   3       ì˜ê°€  ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š How can I assist you today? Feel free..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"feedback_log.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8fb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit run app.py\n",
    "import streamlit as st\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.llms.ollama import Ollama\n",
    "import pandas as pd, os, time, logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "CSV_PATH = \"feedback_log.csv\"\n",
    "\n",
    "# ì„¸ì…˜ ì´ˆê¸°í™”\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if \"memory\" not in st.session_state:\n",
    "    st.session_state.memory = ChatMemoryBuffer.from_defaults(token_limit=2048)\n",
    "if \"feedback_states\" not in st.session_state:\n",
    "    st.session_state.feedback_states = {}\n",
    "if \"just_saved\" not in st.session_state:\n",
    "    st.session_state.just_saved = None  # ë§ˆì§€ë§‰ìœ¼ë¡œ í”¼ë“œë°± ì €ì¥ëœ ë‹µë³€ ë²ˆí˜¸\n",
    "\n",
    "# CSV íŒŒì¼ ì¤€ë¹„\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    pd.DataFrame(columns=[\"ì§ˆë¬¸\", \"ë³„ì \", \"í”¼ë“œë°±\", \"ì¸ê³µì§€ëŠ¥ ë‹µë³€\"]).to_csv(CSV_PATH, index=False)\n",
    "\n",
    "def append_feedback(rating, fb, question, answer):\n",
    "    \"\"\"ì§ˆë¬¸ í¬í•¨í•´ì„œ í”¼ë“œë°± ì €ì¥\"\"\"\n",
    "\n",
    "    # ì¢Œìš° ê³µë°± ì œê±°\n",
    "    try:\n",
    "        fb = str(fb).strip() \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df = pd.DataFrame([{\n",
    "        \"ì§ˆë¬¸\": question,\n",
    "        \"ë³„ì \": rating,\n",
    "        \"í”¼ë“œë°±\": fb,\n",
    "        \"ì¸ê³µì§€ëŠ¥ ë‹µë³€\": answer\n",
    "    }])\n",
    "    df.to_csv(CSV_PATH, mode=\"a\", header=False, index=False)\n",
    "\n",
    "def stream_chat(model, messages):\n",
    "    llm = Ollama(model=model, request_timeout=180.0)\n",
    "    resp = llm.stream_chat(messages)\n",
    "    response, placeholder = \"\", st.empty()\n",
    "    for r in resp:\n",
    "        response += r.delta\n",
    "        placeholder.write(response)\n",
    "    return response\n",
    "\n",
    "def main():\n",
    "    st.title(\"LLM ëª¨ë¸ê³¼ ì±„íŒ…í•˜ê¸° (í”¼ë“œë°± ì•ˆì •í˜•)\")\n",
    "    model = st.sidebar.selectbox(\"ëª¨ë¸ ì„ íƒ\", [\"exaone3.5:2.4b\"])\n",
    "\n",
    "    if st.sidebar.button(\"ì´ˆê¸°í™”\"):\n",
    "        st.session_state.messages = []\n",
    "        st.session_state.memory = ChatMemoryBuffer.from_defaults(token_limit=2048)\n",
    "        st.session_state.feedback_states = {}\n",
    "        st.session_state.just_saved = None\n",
    "        st.success(\"ëª¨ë“  ëŒ€í™” ë° í”¼ë“œë°±ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # === ëŒ€í™” ë Œë”ë§ ===\n",
    "    answer_idx = 0\n",
    "    for i, msg in enumerate(st.session_state.messages):\n",
    "        with st.chat_message(msg[\"role\"]):\n",
    "            st.write(msg[\"content\"])\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                answer_idx += 1\n",
    "                if answer_idx not in st.session_state.feedback_states:\n",
    "                    st.session_state.feedback_states[answer_idx] = {\n",
    "                        \"rating\": None, \"feedback\": \"\", \"done\": False\n",
    "                    }\n",
    "                fs = st.session_state.feedback_states[answer_idx]\n",
    "\n",
    "                # âœ… ë°©ê¸ˆ ì €ì¥ëœ ë‹µë³€ì€ ë°”ë¡œ ì™„ë£Œ ë©”ì‹œì§€ë¡œ ëŒ€ì²´\n",
    "                if st.session_state.just_saved == answer_idx:\n",
    "                    fs[\"done\"] = True\n",
    "                    st.session_state.just_saved = None\n",
    "\n",
    "                # === ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ì¶œ ===\n",
    "                # assistant ë©”ì‹œì§€ ì§ì „ user ë©”ì‹œì§€ë¥¼ ì°¾ì•„ ì—°ê²°\n",
    "                question = \"\"\n",
    "                if i > 0 and st.session_state.messages[i-1][\"role\"] == \"user\":\n",
    "                    question = st.session_state.messages[i-1][\"content\"]\n",
    "\n",
    "                if not fs[\"done\"]:\n",
    "                    st.markdown(\"---\")\n",
    "                    st.markdown(\"**ì´ ë‹µë³€ì€ ì–¼ë§ˆë‚˜ ë§Œì¡±ìŠ¤ëŸ¬ì› ë‚˜ìš”?**\")\n",
    "                    cols = st.columns(5)\n",
    "                    for s, col in enumerate(cols, start=1):\n",
    "                        if col.button(f\"â­ {s}\", key=f\"star_{answer_idx}_{s}\"):\n",
    "                            fs[\"rating\"] = s\n",
    "\n",
    "                    if fs[\"rating\"]:\n",
    "                        st.markdown(f\"ì„ íƒí•œ ë³„ì : {fs['rating']} â­\")\n",
    "                        fs[\"feedback\"] = st.text_area(\"í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”.\",\n",
    "                                                      key=f\"fb_{answer_idx}\",\n",
    "                                                      value=fs[\"feedback\"])\n",
    "                        if st.button(\"í”¼ë“œë°± ì €ì¥\", key=f\"save_{answer_idx}\"):\n",
    "                            append_feedback(fs[\"rating\"], fs[\"feedback\"], question, msg[\"content\"])\n",
    "                            fs[\"done\"] = True\n",
    "                            st.session_state.feedback_states[answer_idx] = fs\n",
    "                            st.session_state.just_saved = answer_idx  # ë‹¤ìŒ ë Œë”ë§ì—ì„œ ì¦‰ì‹œ ì™„ë£Œ í‘œì‹œ\n",
    "                            st.rerun()\n",
    "\n",
    "                else:\n",
    "                    st.caption(\"âœ… ì´ ë‹µë³€ì€ ì´ë¯¸ í”¼ë“œë°± ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # === ì…ë ¥ ì˜ì—­ ===\n",
    "    prompt = st.chat_input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "    if prompt:\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.write(prompt)\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        st.session_state.memory.put(ChatMessage(role=\"user\", content=prompt))\n",
    "\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            start = time.time()\n",
    "            with st.spinner(\"ì‘ë‹µ ìƒì„± ì¤‘...\"):\n",
    "                try:\n",
    "                    history = st.session_state.memory.get_all()\n",
    "                    response = stream_chat(model, history)\n",
    "                    st.write(response)\n",
    "                    st.caption(f\"â± {time.time() - start:.2f}ì´ˆ\")\n",
    "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "                    st.session_state.memory.put(ChatMessage(role=\"assistant\", content=response))\n",
    "                    st.rerun()\n",
    "                except Exception as e:\n",
    "                    st.error(str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë™ì•ˆì˜ ëŒ€í™” ì €ì¥\n",
    "import streamlit as st\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.llms.ollama import Ollama\n",
    "import pandas as pd, os, time, logging, json\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "CSV_PATH = \"feedback_log.csv\"\n",
    "SAVE_FILE = \"conversations.json\"\n",
    "\n",
    "# === ì„¸ì…˜ ì´ˆê¸°í™” ===\n",
    "if \"conversations\" not in st.session_state:\n",
    "    st.session_state.conversations = {}  # {session_name: [messages]}\n",
    "if \"current_chat\" not in st.session_state:\n",
    "    st.session_state.current_chat = None\n",
    "if \"feedback_states\" not in st.session_state:\n",
    "    st.session_state.feedback_states = {}\n",
    "if \"memory\" not in st.session_state:\n",
    "    st.session_state.memory = ChatMemoryBuffer.from_defaults(token_limit=2048)\n",
    "\n",
    "# === JSON ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ===\n",
    "def save_conversations():\n",
    "    with open(SAVE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(st.session_state.conversations, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_conversations():\n",
    "    if os.path.exists(SAVE_FILE):\n",
    "        with open(SAVE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            st.session_state.conversations = json.load(f)\n",
    "\n",
    "# === CSV íŒŒì¼ ì¤€ë¹„ ===\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    pd.DataFrame(columns=[\"ì„¸ì…˜\", \"ë‹µë³€ë²ˆí˜¸\", \"ë³„ì \", \"í”¼ë“œë°±\", \"ì¸ê³µì§€ëŠ¥ ë‹µë³€\"]).to_csv(CSV_PATH, index=False)\n",
    "\n",
    "def append_feedback(session, answer_num, rating, fb, content):\n",
    "    df = pd.DataFrame([{\n",
    "        \"ì„¸ì…˜\": session,\n",
    "        \"ë‹µë³€ë²ˆí˜¸\": answer_num,\n",
    "        \"ë³„ì \": rating,\n",
    "        \"í”¼ë“œë°±\": fb,\n",
    "        \"ì¸ê³µì§€ëŠ¥ ë‹µë³€\": content\n",
    "    }])\n",
    "    df.to_csv(CSV_PATH, mode=\"a\", header=False, index=False)\n",
    "\n",
    "def stream_chat(model, messages):\n",
    "    llm = Ollama(model=model, request_timeout=180.0)\n",
    "    resp = llm.stream_chat(messages)\n",
    "    response, placeholder = \"\", st.empty()\n",
    "    for r in resp:\n",
    "        response += r.delta\n",
    "        placeholder.write(response)\n",
    "    return response\n",
    "\n",
    "# === ë©”ì¸ ===\n",
    "def main():\n",
    "    st.title(\"ğŸ’¬ LLM ëª¨ë¸ê³¼ ì±„íŒ…í•˜ê¸° (ëŒ€í™” ì„¸ì…˜ + í”¼ë“œë°± í¬í•¨)\")\n",
    "\n",
    "    # === ì™¼ìª½ ì‚¬ì´ë“œë°” ===\n",
    "    st.sidebar.header(\"ğŸ“‚ ëŒ€í™” ê´€ë¦¬\")\n",
    "\n",
    "    # ì´ì „ ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    if st.sidebar.button(\"ğŸ”„ ì €ì¥ëœ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°\"):\n",
    "        load_conversations()\n",
    "        st.success(\"ì €ì¥ëœ ëŒ€í™”ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # ìƒˆ ëŒ€í™” ì‹œì‘\n",
    "    if st.sidebar.button(\"â• ìƒˆ ëŒ€í™”\"):\n",
    "        new_name = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        st.session_state.conversations[new_name] = []\n",
    "        st.session_state.current_chat = new_name\n",
    "        st.session_state.feedback_states[new_name] = {}\n",
    "        st.success(f\"ìƒˆ ëŒ€í™” ì‹œì‘: {new_name}\")\n",
    "\n",
    "    # ëŒ€í™” ëª©ë¡\n",
    "    if st.session_state.conversations:\n",
    "        st.sidebar.subheader(\"ğŸ—‚ï¸ ê¸°ì¡´ ëŒ€í™” ëª©ë¡\")\n",
    "        for name in st.session_state.conversations.keys():\n",
    "            if st.sidebar.button(name):\n",
    "                st.session_state.current_chat = name\n",
    "\n",
    "    model = st.sidebar.selectbox(\"ëª¨ë¸ ì„ íƒ\", [\"exaone3.5:2.4b\"])\n",
    "    st.sidebar.button(\"ğŸ’¾ ì „ì²´ ì €ì¥\", on_click=save_conversations)\n",
    "\n",
    "    # === í˜„ì¬ ëŒ€í™” í‘œì‹œ ===\n",
    "    if not st.session_state.current_chat:\n",
    "        st.info(\"ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìƒˆ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.\")\n",
    "        return\n",
    "\n",
    "    session_name = st.session_state.current_chat\n",
    "    messages = st.session_state.conversations[session_name]\n",
    "    feedback_state = st.session_state.feedback_states.setdefault(session_name, {})\n",
    "\n",
    "    st.subheader(f\"ğŸ’­ í˜„ì¬ ëŒ€í™”: {session_name}\")\n",
    "\n",
    "    answer_idx = 0\n",
    "    for msg in messages:\n",
    "        with st.chat_message(msg[\"role\"]):\n",
    "            st.write(msg[\"content\"])\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                answer_idx += 1\n",
    "                fs = feedback_state.setdefault(answer_idx, {\"rating\": None, \"feedback\": \"\", \"done\": False})\n",
    "                if not fs[\"done\"]:\n",
    "                    st.markdown(\"---\")\n",
    "                    st.markdown(\"**ì´ ë‹µë³€ì€ ì–¼ë§ˆë‚˜ ë§Œì¡±ìŠ¤ëŸ¬ì› ë‚˜ìš”?**\")\n",
    "                    cols = st.columns(5)\n",
    "                    for s, col in enumerate(cols, start=1):\n",
    "                        if col.button(f\"â­ {s}\", key=f\"{session_name}_star_{answer_idx}_{s}\"):\n",
    "                            fs[\"rating\"] = s\n",
    "                    if fs[\"rating\"]:\n",
    "                        st.markdown(f\"ì„ íƒí•œ ë³„ì : {fs['rating']} â­\")\n",
    "                        fs[\"feedback\"] = st.text_area(\"í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”.\",\n",
    "                                                      key=f\"{session_name}_fb_{answer_idx}\",\n",
    "                                                      value=fs[\"feedback\"])\n",
    "                        if st.button(\"í”¼ë“œë°± ì €ì¥\", key=f\"{session_name}_save_{answer_idx}\"):\n",
    "                            append_feedback(session_name, answer_idx, fs[\"rating\"], fs[\"feedback\"], msg[\"content\"])\n",
    "                            fs[\"done\"] = True\n",
    "                            feedback_state[answer_idx] = fs\n",
    "                            st.success(\"í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ™Œ\")\n",
    "                            st.rerun()\n",
    "                else:\n",
    "                    st.caption(\"âœ… ì´ ë‹µë³€ì€ ì´ë¯¸ í”¼ë“œë°± ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # === ì‚¬ìš©ì ì…ë ¥ ===\n",
    "    if prompt := st.chat_input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\"):\n",
    "        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        st.session_state.memory.put(ChatMessage(role=\"user\", content=prompt))\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.write(prompt)\n",
    "\n",
    "        # LLM ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            start = time.time()\n",
    "            with st.spinner(\"ì‘ë‹µ ìƒì„± ì¤‘...\"):\n",
    "                try:\n",
    "                    history = st.session_state.memory.get_all()\n",
    "                    response = stream_chat(model, history)\n",
    "                    st.write(response)\n",
    "                    st.caption(f\"â± {time.time() - start:.2f}ì´ˆ\")\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "                    st.session_state.memory.put(ChatMessage(role=\"assistant\", content=response))\n",
    "                except Exception as e:\n",
    "                    st.error(str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rstream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
