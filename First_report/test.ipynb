{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661ef964",
   "metadata": {},
   "source": [
    "CSV 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d54dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>질문</th>\n",
       "      <th>답변번호</th>\n",
       "      <th>별점</th>\n",
       "      <th>피드백</th>\n",
       "      <th>인공지능 답변</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>헬로웅</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>몰라.\\n</td>\n",
       "      <td>헬로! 어떻게 도와드릴까요? 궁금한 점이나 필요한 정보가 있으시다면 언제든지 말씀해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>저기요</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>몰라ㅏㅏㅏㅏㅏ</td>\n",
       "      <td>안녕하세요! LG AI Research의 EXAONE 모델입니다. 도움이 필요하시다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>안녕</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>잘가</td>\n",
       "      <td>안녕하세요! 😊 How can I assist you today? Feel free...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    질문  답변번호  별점      피드백                                            인공지능 답변\n",
       "0  헬로웅     1   3    몰라.\\n  헬로! 어떻게 도와드릴까요? 궁금한 점이나 필요한 정보가 있으시다면 언제든지 말씀해...\n",
       "1  저기요     1   2  몰라ㅏㅏㅏㅏㅏ  안녕하세요! LG AI Research의 EXAONE 모델입니다. 도움이 필요하시다...\n",
       "2   안녕     1   3       잘가  안녕하세요! 😊 How can I assist you today? Feel free..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"feedback_log.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8fb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit run app.py\n",
    "import streamlit as st\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.llms.ollama import Ollama\n",
    "import pandas as pd, os, time, logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "CSV_PATH = \"feedback_log.csv\"\n",
    "\n",
    "# 세션 초기화\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if \"memory\" not in st.session_state:\n",
    "    st.session_state.memory = ChatMemoryBuffer.from_defaults(token_limit=2048)\n",
    "if \"feedback_states\" not in st.session_state:\n",
    "    st.session_state.feedback_states = {}\n",
    "if \"just_saved\" not in st.session_state:\n",
    "    st.session_state.just_saved = None  # 마지막으로 피드백 저장된 답변 번호\n",
    "\n",
    "# CSV 파일 준비\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    pd.DataFrame(columns=[\"질문\", \"별점\", \"피드백\", \"인공지능 답변\"]).to_csv(CSV_PATH, index=False)\n",
    "\n",
    "def append_feedback(rating, fb, question, answer):\n",
    "    \"\"\"질문 포함해서 피드백 저장\"\"\"\n",
    "\n",
    "    # 좌우 공백 제거\n",
    "    try:\n",
    "        fb = str(fb).strip() \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df = pd.DataFrame([{\n",
    "        \"질문\": question,\n",
    "        \"별점\": rating,\n",
    "        \"피드백\": fb,\n",
    "        \"인공지능 답변\": answer\n",
    "    }])\n",
    "    df.to_csv(CSV_PATH, mode=\"a\", header=False, index=False)\n",
    "\n",
    "def stream_chat(model, messages):\n",
    "    llm = Ollama(model=model, request_timeout=180.0)\n",
    "    resp = llm.stream_chat(messages)\n",
    "    response, placeholder = \"\", st.empty()\n",
    "    for r in resp:\n",
    "        response += r.delta\n",
    "        placeholder.write(response)\n",
    "    return response\n",
    "\n",
    "def main():\n",
    "    st.title(\"LLM 모델과 채팅하기 (피드백 안정형)\")\n",
    "    model = st.sidebar.selectbox(\"모델 선택\", [\"exaone3.5:2.4b\"])\n",
    "\n",
    "    if st.sidebar.button(\"초기화\"):\n",
    "        st.session_state.messages = []\n",
    "        st.session_state.memory = ChatMemoryBuffer.from_defaults(token_limit=2048)\n",
    "        st.session_state.feedback_states = {}\n",
    "        st.session_state.just_saved = None\n",
    "        st.success(\"모든 대화 및 피드백이 초기화되었습니다.\")\n",
    "\n",
    "    # === 대화 렌더링 ===\n",
    "    answer_idx = 0\n",
    "    for i, msg in enumerate(st.session_state.messages):\n",
    "        with st.chat_message(msg[\"role\"]):\n",
    "            st.write(msg[\"content\"])\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                answer_idx += 1\n",
    "                if answer_idx not in st.session_state.feedback_states:\n",
    "                    st.session_state.feedback_states[answer_idx] = {\n",
    "                        \"rating\": None, \"feedback\": \"\", \"done\": False\n",
    "                    }\n",
    "                fs = st.session_state.feedback_states[answer_idx]\n",
    "\n",
    "                # ✅ 방금 저장된 답변은 바로 완료 메시지로 대체\n",
    "                if st.session_state.just_saved == answer_idx:\n",
    "                    fs[\"done\"] = True\n",
    "                    st.session_state.just_saved = None\n",
    "\n",
    "                # === 사용자 질문 추출 ===\n",
    "                # assistant 메시지 직전 user 메시지를 찾아 연결\n",
    "                question = \"\"\n",
    "                if i > 0 and st.session_state.messages[i-1][\"role\"] == \"user\":\n",
    "                    question = st.session_state.messages[i-1][\"content\"]\n",
    "\n",
    "                if not fs[\"done\"]:\n",
    "                    st.markdown(\"---\")\n",
    "                    st.markdown(\"**이 답변은 얼마나 만족스러웠나요?**\")\n",
    "                    cols = st.columns(5)\n",
    "                    for s, col in enumerate(cols, start=1):\n",
    "                        if col.button(f\"⭐ {s}\", key=f\"star_{answer_idx}_{s}\"):\n",
    "                            fs[\"rating\"] = s\n",
    "\n",
    "                    if fs[\"rating\"]:\n",
    "                        st.markdown(f\"선택한 별점: {fs['rating']} ⭐\")\n",
    "                        fs[\"feedback\"] = st.text_area(\"피드백을 남겨주세요.\",\n",
    "                                                      key=f\"fb_{answer_idx}\",\n",
    "                                                      value=fs[\"feedback\"])\n",
    "                        if st.button(\"피드백 저장\", key=f\"save_{answer_idx}\"):\n",
    "                            append_feedback(fs[\"rating\"], fs[\"feedback\"], question, msg[\"content\"])\n",
    "                            fs[\"done\"] = True\n",
    "                            st.session_state.feedback_states[answer_idx] = fs\n",
    "                            st.session_state.just_saved = answer_idx  # 다음 렌더링에서 즉시 완료 표시\n",
    "                            st.rerun()\n",
    "\n",
    "                else:\n",
    "                    st.caption(\"✅ 이 답변은 이미 피드백 완료되었습니다.\")\n",
    "\n",
    "    # === 입력 영역 ===\n",
    "    prompt = st.chat_input(\"질문을 입력하세요\")\n",
    "    if prompt:\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.write(prompt)\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        st.session_state.memory.put(ChatMessage(role=\"user\", content=prompt))\n",
    "\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            start = time.time()\n",
    "            with st.spinner(\"응답 생성 중...\"):\n",
    "                try:\n",
    "                    history = st.session_state.memory.get_all()\n",
    "                    response = stream_chat(model, history)\n",
    "                    st.write(response)\n",
    "                    st.caption(f\"⏱ {time.time() - start:.2f}초\")\n",
    "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "                    st.session_state.memory.put(ChatMessage(role=\"assistant\", content=response))\n",
    "                    st.rerun()\n",
    "                except Exception as e:\n",
    "                    st.error(str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그동안의 대화 저장\n",
    "import streamlit as st\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.llms.ollama import Ollama\n",
    "import pandas as pd, os, time, logging, json\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "CSV_PATH = \"feedback_log.csv\"\n",
    "SAVE_FILE = \"conversations.json\"\n",
    "\n",
    "# === 세션 초기화 ===\n",
    "if \"conversations\" not in st.session_state:\n",
    "    st.session_state.conversations = {}  # {session_name: [messages]}\n",
    "if \"current_chat\" not in st.session_state:\n",
    "    st.session_state.current_chat = None\n",
    "if \"feedback_states\" not in st.session_state:\n",
    "    st.session_state.feedback_states = {}\n",
    "if \"memory\" not in st.session_state:\n",
    "    st.session_state.memory = ChatMemoryBuffer.from_defaults(token_limit=2048)\n",
    "\n",
    "# === JSON 저장/불러오기 ===\n",
    "def save_conversations():\n",
    "    with open(SAVE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(st.session_state.conversations, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_conversations():\n",
    "    if os.path.exists(SAVE_FILE):\n",
    "        with open(SAVE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            st.session_state.conversations = json.load(f)\n",
    "\n",
    "# === CSV 파일 준비 ===\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    pd.DataFrame(columns=[\"세션\", \"답변번호\", \"별점\", \"피드백\", \"인공지능 답변\"]).to_csv(CSV_PATH, index=False)\n",
    "\n",
    "def append_feedback(session, answer_num, rating, fb, content):\n",
    "    df = pd.DataFrame([{\n",
    "        \"세션\": session,\n",
    "        \"답변번호\": answer_num,\n",
    "        \"별점\": rating,\n",
    "        \"피드백\": fb,\n",
    "        \"인공지능 답변\": content\n",
    "    }])\n",
    "    df.to_csv(CSV_PATH, mode=\"a\", header=False, index=False)\n",
    "\n",
    "def stream_chat(model, messages):\n",
    "    llm = Ollama(model=model, request_timeout=180.0)\n",
    "    resp = llm.stream_chat(messages)\n",
    "    response, placeholder = \"\", st.empty()\n",
    "    for r in resp:\n",
    "        response += r.delta\n",
    "        placeholder.write(response)\n",
    "    return response\n",
    "\n",
    "# === 메인 ===\n",
    "def main():\n",
    "    st.title(\"💬 LLM 모델과 채팅하기 (대화 세션 + 피드백 포함)\")\n",
    "\n",
    "    # === 왼쪽 사이드바 ===\n",
    "    st.sidebar.header(\"📂 대화 관리\")\n",
    "\n",
    "    # 이전 세션 불러오기\n",
    "    if st.sidebar.button(\"🔄 저장된 대화 불러오기\"):\n",
    "        load_conversations()\n",
    "        st.success(\"저장된 대화를 불러왔습니다.\")\n",
    "\n",
    "    # 새 대화 시작\n",
    "    if st.sidebar.button(\"➕ 새 대화\"):\n",
    "        new_name = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        st.session_state.conversations[new_name] = []\n",
    "        st.session_state.current_chat = new_name\n",
    "        st.session_state.feedback_states[new_name] = {}\n",
    "        st.success(f\"새 대화 시작: {new_name}\")\n",
    "\n",
    "    # 대화 목록\n",
    "    if st.session_state.conversations:\n",
    "        st.sidebar.subheader(\"🗂️ 기존 대화 목록\")\n",
    "        for name in st.session_state.conversations.keys():\n",
    "            if st.sidebar.button(name):\n",
    "                st.session_state.current_chat = name\n",
    "\n",
    "    model = st.sidebar.selectbox(\"모델 선택\", [\"exaone3.5:2.4b\"])\n",
    "    st.sidebar.button(\"💾 전체 저장\", on_click=save_conversations)\n",
    "\n",
    "    # === 현재 대화 표시 ===\n",
    "    if not st.session_state.current_chat:\n",
    "        st.info(\"왼쪽 사이드바에서 새 대화를 시작하거나 불러오세요.\")\n",
    "        return\n",
    "\n",
    "    session_name = st.session_state.current_chat\n",
    "    messages = st.session_state.conversations[session_name]\n",
    "    feedback_state = st.session_state.feedback_states.setdefault(session_name, {})\n",
    "\n",
    "    st.subheader(f\"💭 현재 대화: {session_name}\")\n",
    "\n",
    "    answer_idx = 0\n",
    "    for msg in messages:\n",
    "        with st.chat_message(msg[\"role\"]):\n",
    "            st.write(msg[\"content\"])\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                answer_idx += 1\n",
    "                fs = feedback_state.setdefault(answer_idx, {\"rating\": None, \"feedback\": \"\", \"done\": False})\n",
    "                if not fs[\"done\"]:\n",
    "                    st.markdown(\"---\")\n",
    "                    st.markdown(\"**이 답변은 얼마나 만족스러웠나요?**\")\n",
    "                    cols = st.columns(5)\n",
    "                    for s, col in enumerate(cols, start=1):\n",
    "                        if col.button(f\"⭐ {s}\", key=f\"{session_name}_star_{answer_idx}_{s}\"):\n",
    "                            fs[\"rating\"] = s\n",
    "                    if fs[\"rating\"]:\n",
    "                        st.markdown(f\"선택한 별점: {fs['rating']} ⭐\")\n",
    "                        fs[\"feedback\"] = st.text_area(\"피드백을 남겨주세요.\",\n",
    "                                                      key=f\"{session_name}_fb_{answer_idx}\",\n",
    "                                                      value=fs[\"feedback\"])\n",
    "                        if st.button(\"피드백 저장\", key=f\"{session_name}_save_{answer_idx}\"):\n",
    "                            append_feedback(session_name, answer_idx, fs[\"rating\"], fs[\"feedback\"], msg[\"content\"])\n",
    "                            fs[\"done\"] = True\n",
    "                            feedback_state[answer_idx] = fs\n",
    "                            st.success(\"피드백이 저장되었습니다! 🙌\")\n",
    "                            st.rerun()\n",
    "                else:\n",
    "                    st.caption(\"✅ 이 답변은 이미 피드백 완료되었습니다.\")\n",
    "\n",
    "    # === 사용자 입력 ===\n",
    "    if prompt := st.chat_input(\"질문을 입력하세요\"):\n",
    "        # 사용자 메시지 추가\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        st.session_state.memory.put(ChatMessage(role=\"user\", content=prompt))\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.write(prompt)\n",
    "\n",
    "        # LLM 응답 스트리밍\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            start = time.time()\n",
    "            with st.spinner(\"응답 생성 중...\"):\n",
    "                try:\n",
    "                    history = st.session_state.memory.get_all()\n",
    "                    response = stream_chat(model, history)\n",
    "                    st.write(response)\n",
    "                    st.caption(f\"⏱ {time.time() - start:.2f}초\")\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "                    st.session_state.memory.put(ChatMessage(role=\"assistant\", content=response))\n",
    "                except Exception as e:\n",
    "                    st.error(str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rstream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
